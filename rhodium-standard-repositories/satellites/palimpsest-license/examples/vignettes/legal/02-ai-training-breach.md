# Legal Vignette: The AI Training Consent Breach

## Scenario: Clause 1.2 Violation - Interpretive AI Training Without Consent

**Original Work**: *Code Poetry* (open-source code documentation)
**Creator**: Dr. Elena Vasquez
**Violator**: "DevAI Inc." (AI code generation startup)
**Legal Outcome**: Precedent-setting case on AI training consent

---

## The Facts

Dr. Elena Vasquez, a computer scientist and poet, created *Code Poetry*: technical documentation for her open-source cryptography library written in poetic, metaphorical language that made complex concepts accessible.

Examples:
```python
# The river remembers its source
# Each hash flows from the one before
# Immutable, witnessed, never alone
def hash_chain(data, previous_hash):
    """
    Creates a cryptographic chain where each block
    carries the memory of all that came before.
    Like diaspora—we carry our origins forward.
    """
    ...
```

Her documentation was technically precise but emotionally resonant, helping marginalized developers (women, people of color, neurodivergent coders) feel welcome in technical spaces often hostile to them.

Elena licensed *Code Poetry* under Palimpsest v0.4:

```markdown
## Code Poetry - License Terms

**Author**: Dr. Elena Vasquez
**License**: Palimpsest v0.4
**Purpose**: Technical documentation as emotional and cultural artifact

### Why Palimpsest Instead of Standard Open Source?

Traditional open-source licenses (MIT, Apache, GPL) protect code but not the emotional
and pedagogical intent behind documentation. My poetry-documentation serves multiple purposes:
1. Technical instruction (functional)
2. Cultural inclusion (making tech accessible to marginalized developers)
3. Emotional support (reducing imposter syndrome through poetic framing)

### Permissions

**Non-Interpretive AI** (allowed):
- Search engines indexing documentation
- IDE autocomplete pulling function descriptions
- Translation tools converting to other languages
- Accessibility tools (screen readers, etc.)

**Interpretive AI** (requires explicit consent):
- Training code generation models on the poetic style
- Learning the metaphor-to-code mappings
- Generating new "poetry documentation" based on my patterns
- Using emotional framings to train "empathetic coding assistants"

### Attribution

Code uses are under MIT License (standard open source).
Documentation uses require Palimpsest attribution:
- "Documentation by Dr. Elena Vasquez, Code Poetry project"
- "Poetic style honors marginalized developers"

### Why the Distinction?

AI trained on my poetic documentation would extract:
- How I use metaphor to explain technical concepts
- Cultural references (diaspora, rivers, memory)
- Emotional support language

Without consent, AI companies profit from my labor making tech accessible while
contributing nothing back to that mission. This is extraction, not collaboration.
```

### The Violation

DevAI Inc., a well-funded startup building "CodeCompanion" (an AI pair-programming tool), scraped GitHub for training data. Their dataset included:

- 50 million code repositories
- All associated documentation, including *Code Poetry*
- No consent process, no opt-out mechanism
- No compensation to creators

Their marketing: "CodeCompanion understands your code emotionally, offering empathetic suggestions that reduce developer anxiety."

This "empathy" was trained on Elena's work—her labor making tech emotionally accessible—without her consent or credit.

### Discovery

Elena discovered the violation through a transparency report DevAI published under EU AI Act requirements. Buried in an appendix: a list of training data sources including her repository.

She immediately sent a legal notice:

> "Your AI training dataset includes my *Code Poetry* documentation, licensed under Palimpsest v0.4, which explicitly prohibits interpretive AI training without consent.
>
> **Violations:**
> 1. **Clause 1.2**: CodeCompanion is clearly an interpretive AI system (generates new code and documentation, learns patterns, creates derivatives)
> 2. **No consent requested**: You never contacted me
> 3. **Commercial exploitation**: You're selling "emotional coding support" trained on my unpaid emotional labor
> 4. **Misleading marketing**: You claim CodeCompanion's empathy is your innovation, but it's trained on my work creating inclusive documentation
>
> **Demands:**
> 1. Immediate cessation of all training on *Code Poetry*
> 2. Deletion of model weights derived from my work
> 3. Public disclosure of this violation
> 4. Compensation: £50,000 + ongoing licensing or equity stake
> 5. Consent process for all Palimpsest-licensed works in your dataset"

### DevAI's Defense (Failed)

DevAI's legal team argued:

**Claim 1: "Open source means free for any use, including AI training"**

**Elena's Response:**
> "Open source applies to the CODE (which is under MIT). The DOCUMENTATION is under Palimpsest, which explicitly separates functional and interpretive use. You conflated the two."

**Claim 2: "Fair dealing / fair use for transformative AI research"**

**Elena's Response:**
> "You're not doing research—you're selling a commercial product. 'Transformative' doesn't mean 'any use that changes the work'; it means specific legal criteria you don't meet. And the Palimpsest License explicitly addresses AI training, so contractual terms override fair dealing exceptions."

**Claim 3: "We only trained on publicly available data"**

**Elena's Response:**
> "'Publicly available' doesn't mean 'consent-free.' My documentation is public but licensed. Would you argue that a book in a library is free to photocopy and sell because it's publicly accessible?"

**Claim 4: "Removing one dataset source won't change the model significantly"**

**Elena's Response:**
> "That's not a legal defense. If I steal £10 from you and argue 'you have £10,000, so this doesn't matter,' I've still committed theft. You violated the license; impact on your model is irrelevant to liability."

**Claim 5: "Your license isn't OSI-approved, so it's not enforceable for open-source projects"**

**Elena's Response:**
> "OSI approval isn't a legal requirement—it's a community standard. My code is MIT; my documentation is Palimpsest. I can multi-license. And Palimpsest is enforceable as a standard licensing contract under Dutch law (per the license terms) and UK law (where I'm domiciled)."

### Legal Proceedings

When DevAI refused settlement, Elena sued in Scottish courts (as specified in Palimpsest's jurisdiction clause), bringing:

**1. Breach of License Contract**
- DevAI used work beyond license scope
- License explicitly prohibited AI training without consent
- Contract is enforceable

**2. Copyright Infringement**
- Training involves copying (temporary copies during processing)
- UK/Dutch/EU law recognizes this as reproduction
- No exception for AI training without consent

**3. Database Rights (EU Law)**
- *Code Poetry* as a curated collection of documentation
- Sui generis database right in EU
- Unauthorized extraction violated database rights

**4. Unfair Commercial Practice**
- Marketing CodeCompanion's "empathy" without crediting source
- Misleading consumers about AI's origins

### The Settlement

Facing strong legal precedent from recent EU AI regulation cases and public backlash from developers who supported Elena, DevAI settled:

**1. Immediate Technical Remedies**
- Removed *Code Poetry* from training dataset
- Retrained model from scratch (costly but necessary)
- Implemented consent system for all training data

**2. Financial Compensation**
- £75,000 to Elena
- £25,000 to organizations supporting marginalized developers
- 0.5% equity stake in DevAI (giving Elena ongoing stake in the tool her work helped create)

**3. Attribution & Credit**
- Public acknowledgment that Elena's work contributed to early models
- Credit in product documentation: "Initial training included work by marginalized developer advocates"
- Case study in their ethics documentation

**4. Industry Standards**
- DevAI published their new consent framework as open standard
- Lobbied for AI training consent requirements in industry groups
- Funded development of automated license detection tools

---

## Legal Analysis

### Why This Case Succeeded

**1. Clear License Language**
Elena's Palimpsest metadata explicitly distinguished non-interpretive (permitted) from interpretive (consent required) AI uses. DevAI couldn't claim ambiguity.

**2. Multi-License Strategy**
By putting code under MIT and documentation under Palimpsest, Elena demonstrated intentional licensing choices. DevAI couldn't argue "you meant everything to be open source."

**3. Documented Commercial Harm**
Elena showed DevAI marketed "empathetic AI" features directly trained on her emotional labor, proving commercial exploitation.

**4. Public Support**
The developer community rallied behind Elena, creating PR pressure. Prominent open-source maintainers threatened to add "no AI training" clauses inspired by Palimpsest.

**5. Regulatory Timing**
The case coincided with EU AI Act implementation, making courts more receptive to AI training consent arguments.

### Precedent Set

This case established:

**1. "Open Source" ≠ "Train AI Freely"**
Open-source licenses govern code use, not necessarily AI training. Creators can separate functional (code) and interpretive (AI training) permissions.

**2. Palimpsest Licenses Are Enforceable**
Courts recognized Palimpsest's AI consent clauses as valid contract terms, not unenforceable "moral licenses."

**3. Emotional Labor Has Economic Value**
Elena's work making tech accessible to marginalized people was recognized as valuable labor worthy of compensation when extracted by AI.

**4. "Publicly Available" ≠ "Consent-Free"**
GitHub repos, public websites, and other accessible works still have licenses. Accessibility doesn't imply consent.

**5. Transparency Enables Enforcement**
DevAI's EU-mandated transparency report allowed Elena to discover the violation. This strengthened arguments for AI training transparency requirements.

---

## Practical Lessons

### For Open-Source Creators

**Do:**
- Consider dual licensing: permissive for code, protective for documentation/data/creative elements
- Explicitly state AI training permissions in LICENSE files
- Use Palimpsest for documentation, READMEs, tutorials, or other creative/pedagogical work
- Monitor AI transparency reports and dataset disclosures
- Join collective enforcement efforts (individual creators have more power together)

**Don't:**
- Assume MIT/Apache/GPL cover AI training (they weren't written with AI in mind)
- Leave licensing ambiguous (companies will interpret in their favor)
- Put all your work under one license without considering different use cases

### For AI Companies

**Do:**
- Implement consent systems BEFORE scraping training data
- Respect license terms, even if you disagree with them philosophically
- Offer compensation (payment, equity, credit) to creators whose work you train on
- Publish transparent training data sources
- Budget for licensing (free training data is often stolen training data)

**Don't:**
- Claim "publicly available = consent"
- Hide behind "transformative use" for commercial products
- Scrape first, ask forgiveness later
- Assume open-source licenses cover all uses
- Market AI features without crediting the human labor that enabled them

### For Platform Operators (GitHub, GitLab, etc.)

**Do:**
- Give users clear AI training opt-out mechanisms
- Detect and display license types (including Palimpsest)
- Warn AI companies about non-permissive licenses
- Provide tools for creators to monitor how their work is used
- Support creators enforcing their licenses

**Don't:**
- Sell user data/code to AI companies without consent
- Assume your terms of service override user licenses
- Make opt-out burdensome or hidden
- Prioritize AI company relationships over creator rights

---

## Discussion Questions

1. Should "open source" inherently include AI training permissions? Or should creators be able to allow code use while restricting AI training?

2. If retraining AI models from scratch (without violating content) is expensive, should that reduce penalties? Or is expense irrelevant to liability?

3. Elena's emotional labor made tech accessible. Should AI companies have a special duty to compensate labor that serves marginalized communities?

4. What if CodeCompanion, after retraining, produces similar "empathetic" outputs without Elena's data? Is that still exploitation?

5. Should there be a compulsory licensing scheme for AI training (companies can train but must pay set rates) or should consent remain fully opt-in?

---

**License Note**: This vignette is licensed under CC BY-SA 4.0. *Code Poetry*, Dr. Elena Vasquez, DevAI Inc., and CodeCompanion are fictional, created to illustrate AI training consent enforcement under Palimpsest.
